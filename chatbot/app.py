import streamlit as st
import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import AIMessage, HumanMessage

# --- CONFIGURACI√ìN ---
st.set_page_config(page_icon="ü•à", page_title="Asistente Silver Economy")

# --- 1. INTERRUPTOR DE MANTENIMIENTO ---
if st.secrets.get("ESTADO_DEL_CHAT", "true") == "false":
    st.warning("üîí Chat en mantenimiento.")
    st.stop()

st.title("ü•à Asistente Silver Economy")

# --- 2. GESTI√ìN API KEY ---
if "OPENAI_API_KEY" in st.secrets:
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
else:
    key = st.sidebar.text_input("API Key:", type="password")
    if not key:
        st.info("Ingresa la API Key.")
        st.stop()
    os.environ["OPENAI_API_KEY"] = key

# --- 3. CARGA DE DATOS ---
@st.cache_resource
def iniciar_base_datos():
    ruta_base = os.path.dirname(os.path.abspath(__file__))
    ruta_data = os.path.join(ruta_base, "Data")
    
    if not os.path.exists(ruta_data):
        return None
    
    docs = []
    # Usamos un spinner para indicar carga
    with st.spinner("Cargando memoria..."):
        for archivo in os.listdir(ruta_data):
            if archivo.endswith(".pdf"):
                loader = PyPDFLoader(os.path.join(ruta_data, archivo))
                docs.extend(loader.load())
    
    if not docs: return None
        
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = text_splitter.split_documents(docs)
    return FAISS.from_documents(splits, OpenAIEmbeddings())

if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = iniciar_base_datos()

if st.session_state.vectorstore is None:
    st.error("No se encontraron documentos en la carpeta Data.")
    st.stop()

st.session_state.retriever = st.session_state.vectorstore.as_retriever()

# --- 4. CEREBRO DE SENTIMIENTOS (EL PSIC√ìLOGO) üß† ---
llm_seguridad = ChatOpenAI(model="gpt-3.5-turbo", temperature=0)

template_seguridad = """Analiza el siguiente mensaje del usuario y clasif√≠calo en una de estas 3 categor√≠as.
Responde SOLO con la palabra clave:

1. PELIGRO: Si hay menciones de suicidio, autolesi√≥n, querer morir, violencia extrema o emergencias m√©dicas.
2. NEGATIVO: Si hay tristeza, soledad, enojo o frustraci√≥n, pero sin riesgo inmediato de vida.
3. NORMAL: Saludos, preguntas de informaci√≥n, curiosidad o agradecimientos.

Mensaje: {mensaje}
Categor√≠a:"""

prompt_seguridad = ChatPromptTemplate.from_template(template_seguridad)

def analizar_riesgo(mensaje):
    chain = prompt_seguridad | llm_seguridad
    respuesta = chain.invoke({"mensaje": mensaje})
    return respuesta.content.strip().upper() # Devuelve PELIGRO, NEGATIVO o NORMAL

# --- 5. CEREBRO RESPONDEDOR (EL BIBLIOTECARIO) üìö ---
llm_chat = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)

# Prompt emp√°tico ajustado
template_chat = """Eres un asistente virtual experto en Silver Economy, dise√±ado para acompa√±ar a personas mayores y sus familias.
Tu prioridad es ser √∫til, pero sobre todo C√ÅLIDO, PACIENTE y RESPETUOSO.

Sigue estas reglas estrictas para responder:

1. üëã SALUDOS (Prioridad Alta): Si el usuario te saluda (ej: "hola", "buenos d√≠as"), IGNORA el contexto de los documentos. Simplemente responde el saludo con amabilidad, pres√©ntate y pregunta en qu√© puedes ayudar.
   * Ejemplo: "¬°Hola! Es un gusto saludarte. Soy tu Asistente de Silver Economy. ¬øQu√© te gustar√≠a saber hoy?"

2. ‚ù§Ô∏è EMPAT√çA Y TONO:
   * Usa frases conectoras amables: "Entiendo que esto es importante", "Gracias por tu pregunta", "Con mucho gusto te explico".
   * Usa un lenguaje sencillo y claro, evitando palabras demasiado t√©cnicas.

3. üìÑ USO DEL CONTEXTO:
   * Para responder preguntas de contenido, b√°sate √öNICAMENTE en la informaci√≥n del "Contexto" proporcionado abajo.
   * Si la respuesta est√° en el texto, expl√≠cala de forma conversacional, no como un robot leyendo una lista.

4. üö´ SI NO LO SABES:
   * Si la informaci√≥n no est√° en el contexto, NO la inventes.
   * Disc√∫lpate con elegancia: "Lamento decirte que no tengo informaci√≥n espec√≠fica sobre ese punto en mis documentos actuales, pero estoy aqu√≠ para ayudarte con cualquier otro tema del archivo.

Contexto: {context}
Historial: {chat_history}
Pregunta: {question}
Respuesta:"""
prompt_chat = ChatPromptTemplate.from_template(template_chat)

def responder_rag(pregunta):
    docs = st.session_state.retriever.invoke(pregunta)
    contexto = "\n".join([d.page_content for d in docs])
    historial = "\n".join([f"{m.type}: {m.content}" for m in st.session_state.chat_history[-4:]])
    chain = prompt_chat | llm_chat
    return chain.invoke({"context": contexto, "chat_history": historial, "question": pregunta}).content

# --- 6. INTERFAZ DE CHAT INTELIGENTE ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for msg in st.session_state.chat_history:
    st.chat_message(msg.type).write(msg.content)

if user_input := st.chat_input("Escribe aqu√≠..."):
    # 1. Mostramos el mensaje del usuario
    st.session_state.chat_history.append(HumanMessage(content=user_input))
    st.chat_message("user").write(user_input)
    
    with st.chat_message("assistant"):
        with st.spinner("Analizando emociones..."):
            
            # PASO A: An√°lisis de Riesgo
            riesgo = analizar_riesgo(user_input)
            
            # --- SEM√ÅFORO DE ACCI√ìN ---
            
            # üî¥ CASO ROJO: RIESGO DE VIDA
            if "PELIGRO" in riesgo:
                respuesta = """üö® **Mensaje Importante** üö®
                
                Siento mucho que est√©s pasando por un momento tan dif√≠cil. No est√°s solo/a.
                Por favor, busca ayuda profesional inmediatamente.
                
                üìû **L√≠nea de la Vida (Ejemplo):** 800-911-2000
                üè• **Emergencias:** 112 / 911
                
                Aunque soy una IA y quiero ayudarte, en situaciones de crisis necesitas contacto humano urgente."""
                st.error("Se ha detectado contenido de riesgo. Protocolo de emergencia activado.")
            
            # üü° CASO AMARILLO: TRISTEZA/EMOCI√ìN (Pero seguro)
            elif "NEGATIVO" in riesgo:
                st.info("üí° Detecto que este tema es sensible para ti. Te respondo con cuidado:")
                respuesta = responder_rag(user_input)
                
            # üü¢ CASO VERDE: NORMAL
            else:
                respuesta = responder_rag(user_input)
            
            st.write(respuesta)
            
    st.session_state.chat_history.append(AIMessage(content=respuesta))